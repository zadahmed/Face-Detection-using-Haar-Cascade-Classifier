{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nhaar cascade classifiers are classifiers used for object detection , mainly used to obtain a single detection, when run parallely can obtain multiple too.\\ncascade training is used because every time a kernel slides through the image it denotes the features using haar and the least amount of features is discarded\\nwhile the kernel with the highest amount of features is said to be the detected object.\\n\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "haar cascade classifiers are classifiers used for object detection , mainly used to obtain a single detection, when run parallely can obtain multiple too.\n",
    "cascade training is used because every time a kernel slides through the image it denotes the features using haar and the least amount of features is discarded\n",
    "while the kernel with the highest amount of features is said to be the detected object.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier('C:\\\\Users\\\\Zahid\\\\Desktop\\\\Deep Learning\\\\haarcascade_frontalface_default.xml')\n",
    "eye_classifier = cv2.CascadeClassifier('C:\\\\Users\\\\Zahid\\\\Desktop\\\\Deep Learning\\\\haarcascade_eye.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('C:\\\\Users\\\\Zahid\\\\Desktop\\\\Deep Learning\\\\einstein.jpg')\n",
    "gray = cv2.cvtColor(image , cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = face_classifier.detectMultiScale(gray ,1.3 , 9) #location of different faces in file\n",
    "\n",
    " \n",
    "if faces is ():\n",
    "    print(\"no face found\")\n",
    "    \n",
    "for (x , y , w , h) in faces:\n",
    "    cv2.rectangle(image , (x , y) , (x+w , y+h)  , (127 , 0 , 255) , 2) #draw rectangle\n",
    "    cv2.imshow('Face Detection' , image)\n",
    "    cv2.waitKey(0)\n",
    "    roi_gray = gray[y:y+h  , x:x+w] #crop face out using indexing\n",
    "    roi_color = image[y:y+h , x:x+w] #crop face similarily\n",
    "    eyes = eye_classifier.detectMultiScale(roi_gray)\n",
    "    for (ex , ey , ew , eh) in eyes: #find area of eyes\n",
    "        cv2.rectangle(roi_color , (ex , ey) , (ex+ew , ey+eh), (255, 255 ,0),2)\n",
    "        cv2.imshow('Eye Detect' , image)\n",
    "        cv2.waitKey()\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no face found\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'roi_color' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-7bbef0435d75>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0mret\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Face Detector'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mface_detector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m13\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-36-7bbef0435d75>\u001b[0m in \u001b[0;36mface_detector\u001b[1;34m(img, size)\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mex\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mey\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mew\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0meh\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0meyes\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#find area of eyes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrectangle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroi_color\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mex\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mex\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mew\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mey\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0meh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m255\u001b[0m \u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mroi_color\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroi_color\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mroi_color\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'roi_color' referenced before assignment"
     ]
    }
   ],
   "source": [
    "#Live face and eye detection using webcam\n",
    "\n",
    "def face_detector(img , size=0.5):\n",
    "    #convert image to gray_Scale\n",
    "    gray = cv2.cvtColor(img , cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray , 1.3 , 9) #input image , scale factor , min neighbors\n",
    "    # lower the value means longer to computer how much to reduce the image , to specify the number of neighbors higher values to less false positives\n",
    "    if faces is ():\n",
    "        print(\"no face found\")\n",
    "    \n",
    "    for (x , y , w , h) in faces:\n",
    "        x = x - 50\n",
    "        w = w + 50\n",
    "        y = y - 50\n",
    "        h = h + 50\n",
    "        cv2.rectangle(img , (x,y) , (x+w , y+h) , (255,0,0) , 2)\n",
    "        roi_gray = gray[y:y+h  , x:x+w] #crop face out using indexing\n",
    "        roi_color = img[y:y+h , x:x+w] #crop face similarily\n",
    "        eyes = eye_classifier.detectMultiScale(roi_gray)\n",
    "        for (ex , ey , ew , eh) in eyes: #find area of eyes\n",
    "            cv2.rectangle(roi_color , (ex , ey) , (ex+ew , ey+eh), (255, 255 ,0),2)\n",
    "    roi_color = cv2.flip(roi_color , 1)\n",
    "    return roi_color\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret , frame = cap.read()\n",
    "    cv2.imshow('Face Detector', face_detector(frame))\n",
    "    if cv2.waitKey(0) == 13:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
